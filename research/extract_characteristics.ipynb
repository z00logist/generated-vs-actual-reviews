{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ae511e-2a7f-438a-8854-23a3d7b6a25f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda737d-cf65-4848-a05a-3c4371e72a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e35c5f-fcac-4d49-bd7c-2229ec9e50df",
   "metadata": {},
   "source": [
    "# Read Our Parallel Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c58e0b-0482-4f5c-88be-e94f6c881c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/parallel_dataset.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de39074-5339-4e30-ac54-e7951a35218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb471a-f406-4d4f-bc84-5b1bb52e8ad7",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b8057-4ba0-432f-a741-0183e1ae3c09",
   "metadata": {},
   "source": [
    "## Extract Linguistic Characteristics from each of texts via Pymorphy and Natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5edb09e-7ab1-4012-8217-31d0b50afe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "segmenter = natasha.Segmenter()\n",
    "emb = natasha.NewsEmbedding()\n",
    "morph_tagger = natasha.NewsMorphTagger(emb)\n",
    "syntax_parser = natasha.NewsSyntaxParser(emb)\n",
    "\n",
    "\n",
    "def get_dependency_relations(text: str) -> t.Sequence[str]:\n",
    "    doc = natasha.Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    doc.parse_syntax(syntax_parser)\n",
    "    \n",
    "    dep_relations = [_.rel for _ in doc.tokens]\n",
    "    return dep_relations\n",
    "\n",
    "\n",
    "def process_review(review: str) -> t.Sequence[t.Mapping[str, str]]:\n",
    "    words = review.split()\n",
    "    dep_relations = get_dependency_relations(review)\n",
    "    \n",
    "    processed_words = []\n",
    "    for word, dep in zip(words, dep_relations):\n",
    "        p = morph.parse(word)[0]\n",
    "        processed_word = {\n",
    "            \"word\": word,\n",
    "            \"lemma\": p.normal_form,\n",
    "            \"pos\": p.tag.POS,\n",
    "            \"morph\": str(p.tag),\n",
    "            \"dep\": dep  \n",
    "        }\n",
    "        processed_words.append(processed_word)\n",
    "    return processed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696456e0-6298-481c-a27d-a0678a4f0559",
   "metadata": {},
   "source": [
    "## Convert to Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba4155-8541-450c-bc39-4e7f7c6d5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv_format(processed_review: t.Sequence[t.Mapping[str, str]]) -> pd.DataFrame:\n",
    "    max_length = max(len(review) for review in processed_review)\n",
    "    columns = [\"sentence\"]\n",
    "    data = {\"sentence\": []}\n",
    "\n",
    "    for i in range(1, max_length + 1):\n",
    "        for attr in [\"word\", \"lemma\", \"pos\", \"morph\"]:\n",
    "            column_name = f\"{attr}{i}\"\n",
    "            columns.append(column_name)\n",
    "            data[column_name] = []\n",
    "\n",
    "    for review in processed_review:\n",
    "        sentence = \" \".join(word[\"word\"] for word in review)\n",
    "        row = {\"sentence\": sentence}\n",
    "        for i, word in enumerate(review, start=1):\n",
    "            for attr in [\"word\", \"lemma\", \"pos\", \"morph\"]:\n",
    "                row[f\"{attr}{i}\"] = word[attr]\n",
    "        for key in data.keys():\n",
    "            data[key].append(row.get(key, None))\n",
    "\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a5e83-8276-4cdb-8a7d-f342bc494a8e",
   "metadata": {},
   "source": [
    "## The Preprocessing Itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49addac8-fd18-431a-b934-a7c714027c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_gen_reviews = df[\"gen_review\"].apply(process_review)\n",
    "preprocessed_actual_reviews = df[\"actual_review\"].apply(process_review)\n",
    "\n",
    "csv_ready_gen_reviews = convert_to_csv_format(preprocessed_gen_reviews)\n",
    "csv_ready_actual_reviews = convert_to_csv_format(preprocessed_actual_reviews)\n",
    "\n",
    "csv_ready_gen_reviews.to_csv(\"data/gen_linguistic_char.csv\", index=False)\n",
    "csv_ready_actual_reviews.to_csv(\"data/actual_linguistic_char.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
